{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import string\n",
    "import re\n",
    "from matplotlib import pyplot\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataLoader(dataType):\n",
    "    '''function to load the data'''\n",
    "    tList = []\n",
    "    label = []\n",
    "    for name in glob.glob(os.getcwd()+\"//Dataset//\"+dataType+\"//neg//*\"):\n",
    "        with open(name,encoding=\"utf8\") as f:\n",
    "            text = f.readlines()\n",
    "            tList.append(text[0])\n",
    "            label.append(0)\n",
    "    \n",
    "    for name in glob.glob(os.getcwd()+\"//Dataset//\"+dataType+\"//pos//*\"):\n",
    "        with open(name,encoding=\"utf8\") as f:\n",
    "            text = f.readlines()\n",
    "            tList.append(text[0])\n",
    "            label.append(1)\n",
    "    \n",
    "    df = pd.DataFrame(list(zip(tList,label)),columns = [\"Text\",\"Label\"])\n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data into training and testing sets\n",
    "test = dataLoader(\"test\")\n",
    "train = dataLoader(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reusing from PA3\n",
    "def loadPositveNegativeStop():\n",
    "    '''function to stop words'''\n",
    "    stop = []\n",
    "    \n",
    "                \n",
    "    for name in glob.glob(os.getcwd()+\"//Dataset//stop_words.txt\"):\n",
    "        with open(name,encoding=\"utf8\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                stop.append(line.strip())\n",
    "    \n",
    "    return stop\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = loadPositveNegativeStop() #loading stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reusing from PA3\n",
    "def preprocessing(text):\n",
    "    '''function to process the data'''\n",
    "    \n",
    "    #lowercasing\n",
    "    text = text.lower()\n",
    "    \n",
    "    #removing everything except alphabets\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \",text) \n",
    "    \n",
    "    for word in stop:\n",
    "        #removing stopwords using regex\n",
    "        regex = r'\\b'+word+r'\\b'\n",
    "        text = re.sub(regex,\" \",text)\n",
    "    \n",
    "    #removing punctuation\n",
    "    for word in string.punctuation:\n",
    "        text = text.replace(word,\" \")\n",
    "    \n",
    "    text = text.strip()\n",
    "    return text\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying pre-processing\n",
    "train['Ptext'] = train['Text'].apply(preprocessing)\n",
    "test['Ptext'] = test['Text'].apply(preprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for speeding purposes\n",
    "# train.to_pickle(\"train.pkl\")\n",
    "# test.to_pickle(\"test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for speeding purposes\n",
    "# train = pd.read_pickle(\"train.pkl\")\n",
    "# test = pd.read_pickle(\"test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDictionary(data):\n",
    "    '''function to create dictionary with sums'''\n",
    "    \n",
    "    V = Counter()\n",
    "    sums = 0\n",
    "    for text in data['Ptext']:\n",
    "        text = text.split()\n",
    "        sums+=len(text)\n",
    "        for chars in text:\n",
    "            V[chars]+=1\n",
    "        \n",
    "    return V,sums\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.unique(train['Label'].ravel()) #Getting unique classes from data as said in the algorithm\n",
    "D = train[['Ptext','Label']] #Creating Document as specififed in the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainNaiveBayes(D,C):\n",
    "    '''function to train naive bayes as by the provided algorithm'''\n",
    "    #D is the documents\n",
    "    #C is the classes\n",
    "    #Claculating loppriors\n",
    "    logprior = [0,0]\n",
    "    Ndoc = len(D)\n",
    "    Nc = [0,0]\n",
    "    \n",
    "    for classes in C:\n",
    "        Nc[classes] = len(D[D['Label']==classes])\n",
    "    \n",
    "    for classes in C:\n",
    "        logprior[classes] = np.log(Nc[classes]/Ndoc)\n",
    "    \n",
    "    #creating dictionary\n",
    "    V,_ = createDictionary(D)\n",
    "    \n",
    "    #Creating bigDoc\n",
    "    V0Doc,sums0 = createDictionary(D[D['Label']==0])\n",
    "    V1Doc,sums1 = createDictionary(D[D['Label']==1])\n",
    "    \n",
    "    bigDoc = [V0Doc,V1Doc]\n",
    "    \n",
    "    #Calculating loglikelihood\n",
    "    loglikelihood = Counter()\n",
    "    \n",
    "    for word in V:\n",
    "        \n",
    "        count_0 = bigDoc[0][word]\n",
    "        count_1 = bigDoc[1][word]\n",
    "        \n",
    "        loglikelihood[(word,0)] = np.log((count_0+1)/(sums0+len(V)))\n",
    "        loglikelihood[(word,1)] = np.log((count_1+1)/(sums1+len(V)))\n",
    "        \n",
    "    return logprior,loglikelihood,V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprior,loglikelihood,V = TrainNaiveBayes(D,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestNaiveBayes(test,logprior=logprior,loglikelihood=loglikelihood,C=C,V=V):\n",
    "    '''function to test naive bayes'''\n",
    "    sums = [0,0]\n",
    "    keys = V.keys()\n",
    "    test = test.split()\n",
    "    for classes in C:\n",
    "        #Adding logprior\n",
    "        sums[classes] = logprior[classes]\n",
    "        for word in test: \n",
    "            #ignoring words that are not in the dictionary\n",
    "            if word in keys:\n",
    "                sums[classes]+= loglikelihood[(word,classes)]\n",
    "    #returning the max probability class label and its probability\n",
    "    sums = np.array(sums)\n",
    "    return np.argmax(sums),np.max(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing data is: 82.528\n"
     ]
    }
   ],
   "source": [
    "#Getting prediciton for the data and printing the accuracy\n",
    "ypred = []\n",
    "ytrue = test['Label'].ravel()\n",
    "for text in test['Ptext']:\n",
    "    pred,_ = TestNaiveBayes(text)\n",
    "    ypred.append(pred)\n",
    "ypred = np.array(ypred)\n",
    "accuracy = (ypred==ytrue).mean()\n",
    "print(\"Accuracy on testing data is:\",accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(Ytrue,Ypred):\n",
    "    '''function to print confusion matrix'''\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0 \n",
    "    fn = 0 \n",
    "    \n",
    "    for x,y in zip(Ytrue,Ypred):\n",
    "        \n",
    "        if x==0 and y==0:\n",
    "            tp+=1\n",
    "        if x==1 and y==1:\n",
    "            tn+=1\n",
    "        if x==0 and y==1:\n",
    "            fn+=1\n",
    "        if x==1 and y==0:\n",
    "            fp+=1\n",
    "    \n",
    "    array = np.array([[tp,fn],[fp,tn]])\n",
    "    print(array)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix on training data is:\n",
      "[[11022  1478]\n",
      " [ 2890  9610]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix on training data is:\")\n",
    "confusionMatrix(ytrue,ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the training and testing corpus\n",
    "train_corpus = list(train['Ptext'].ravel())\n",
    "test_corpus = list(test['Ptext'].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an instance of count Vectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting and transforming training data and then simply fitting the testing data\n",
    "XTrain = vectorizer.fit_transform(train_corpus)\n",
    "XTest = vectorizer.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting labels into arrays\n",
    "YTrain = train['Label'].ravel()\n",
    "YTest = test['Label'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating multinomial naive bayes and fitting on training data\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(XTrain,YTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing data is: 82.528\n",
      "The confusion matrix is as follows\n",
      "[[11026  1474]\n",
      " [ 2894  9606]]\n"
     ]
    }
   ],
   "source": [
    "#Getting mrediction from the model on testing data\n",
    "#Calculating accuracy and printing the confusion matrix\n",
    "ypredp2 = mnb.predict(XTest)\n",
    "acc = accuracy_score(YTrain,ypredp2)\n",
    "print(\"Accuracy on testing data is:\",acc*100)\n",
    "print(\"The confusion matrix is as follows\")\n",
    "print(confusion_matrix(YTrain,ypredp2,labels=[0,1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
